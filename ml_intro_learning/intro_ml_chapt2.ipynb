{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "id": "eef3595ecb7d53f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analyzes the the real world breast cancer dataset in KNN model",
   "id": "8b2643c6d76e51bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify= cancer.target, random_state  =66)\n",
    "\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "\n",
    "neighborhood_setting = range(1, 11)\n",
    "\n",
    "for n in neighborhood_setting:\n",
    "     # Fit each KNN model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n)\n",
    "    clf.fit(X_train, Y_train)\n",
    "     # record the accuracy for each model with different hyperparameter\n",
    "    training_accuracy.append(clf.score(X_train, Y_train))\n",
    "    testing_accuracy.append(clf.score(X_test, Y_test))\n",
    "\n",
    "# Draw the plot to illustrate the comparison between training accuracy and testing accuracy\n",
    "\n",
    "plt.plot(neighborhood_setting, training_accuracy, label=\"Training Accuracy\")\n",
    "plt.plot(neighborhood_setting, testing_accuracy, label=\"Testing Accuracy\")\n",
    "plt.xlabel(\"N-neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n"
   ],
   "id": "295c43316e66b18b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When the hyperparameter is 1, that only consider the nearest 1 neighbor, the training accuracy is 100%\n",
    "As the number of neighbors considered increases, the training accuracy falls, which means that the model gradually becomes simpler. Model with one neighbor has bad testing accuracy, so it is too complicated.\n",
    "\n",
    "However, the training accuracy bottoms at about 0.94 in the maximum neighbors number, model is too simple at that point.\n",
    "\n",
    "The best performance point is in the middle, when the number of neighbors comes to six.\n",
    "\n",
    "\n"
   ],
   "id": "1159e4763067b323"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analyzes KNN Regressor",
   "id": "f30fe874275aa71e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Generates 100 data points distributing between -3 and 3\n",
    "line = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
    "\n",
    "for n_neighbors, ax in zip([1,3,9], axes):\n"
   ],
   "id": "936af79590142f11"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
